description: train clip model on google cc and sbu

target:
  service: amlk8s
  name: ms-shared-v100
  
# target:
#   vc: msrhyper
#   service: amlk8s
#   name: itphyperdgxcl1

environment:
  # image: pengchuanzhang/maskrcnn:py3.7-cuda10.0-pytorch1.4
  # image: jwyang/videotransformer:cuda10.0-pytorch1.4-py3.7
  # image: jw2yang/video:v0.2
  image: jw2yang/video-pytorch1.7:v0.1

storage:
  test_data_storage:
    storage_account_name: vlpdatasets
    container_name: data
  model_storage:
    storage_account_name: vlpdatasets
    container_name: model    
  output_storage:
    storage_account_name: projects4jw
    container_name: phillytools

code:
  # local directory of the code. this will be uploaded to the server.
  # $CONFIG_DIR is expanded to the directory of this config file
  local_dir: ./

search:
  job_template:
    name: train_swin_large_transformer
    sku: G16
    sku_count: 1
    # aml_mpirun:
    #   process_count_per_node: 1
    #   # AML only supports: OpenMpi or IntelMpi
    #   communicator: "OpenMpi"
    command:
    - ulimit -n 4096
    - pip install timm antialiased-cnns bcolz ftfy regex tqdm
    - pip install opencv-python==4.4.0.46 termcolor==1.1.0 yacs==0.1.8
    - export MKL_SERVICE_FORCE_INTEL=1
    - MKL_THREADING_LAYER=GNU python -m torch.distributed.launch --nproc_per_node {ngpus} --master_port 12345 main.py
      --data-path /msrhyper-ddn/msrhyper/jianwyan/imagenet_zip/2012
      --batch-size {batch_size}
      --cfg configs/swin_large_patch4_window12_384_train.yaml 
      --resume {resume_model}
      --opts 
        TRAIN.EPOCHS 100 
        TRAIN.BASE_LR {lr} 
        MODEL.TYPE {model_type} 
        MODEL.SWIN.POOL_METHOD {pool_method} 
        MODEL.SWIN.POOL_STAGES '[0,1,2,3]' 
        MODEL.SWIN.PYRAMID_LEVELS '[1, 1, 1, 1]' 
        MODEL.SWIN.EXPAND_LAYER "even" 
        MODEL.SWIN.EXPAND_SIZE {esize} 
        MODEL.SWIN.UNFOLD_WINDOWS '[9, 5, 3, 1]'
      --zip
    submit_args:
      container_args:
        shm_size: 2048g
  max_trials: 36
  type: grid          
  params:
    - name: ngpus
      spec: discrete
      values: [16]  
    - name: batch_size
      spec: discrete
      values: [32]
    - name: lr
      spec: discrete
      values: [1e-5]
    - name: model_type
      spec: discrete
      values: ['swinv23']      
    - name: pool_method
      spec: discrete
      values: ['fc']   
    - name: esize
      spec: discrete
      values: [0]       
    - name: resume_model
      spec: discrete
      values: [
        /mnt/model_storage/swin-transformer/swin_large_patch4_window12_384_22k.pth, 
        # "/mnt/output_storage/projects/visual_bakcbone/train_focal_large_continue_from_e40/pt-results/visual_bakcbone-33e2a88e-train_focal_large_continue_from_e40-train_swin_tiny_transformer-b0c8ba61/imagenet22k/focal_large_patch4_window7_224/model_best.pth"
      ] 